shiny::runApp()
runApp()
runApp()
runApp()
library(tm)
library(dplyr)
library(wordcloud)
library("wordcloud2")
tweet_cleaned = read.csv("/Users/nihaozheng/Desktop/Visualization/project/twitter/tweet.csv")
tweet_sub = tweet_cleaned[1:18,]
tweet_content = toString(tweet_sub$Content)
docs = Corpus(VectorSource(tweet_content)) %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(tolower)  %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(stripWhitespace) %>%
tm_map(PlainTextDocument)
tdm = TermDocumentMatrix(docs) %>%
as.matrix()
content = as.matrix(tdm[,1])
content = as.matrix(content[order(content, decreasing=TRUE),])
print("head(Whole Book)")
print(head(content))
print("Whole Book's most occuring words:")
print(head(rownames(content)))
pal <- brewer.pal(9, "YlGnBu")
pal <- pal[-(1:3)]
wordcloud(rownames(content), content, min.freq =100, scale=c(5, .2), random.order = FALSE, random.color = FALSE, colors= pal)
content2 = data.frame(content)
content2=rownames_to_column(content2, var = "word")
wordcloud2(content2,size=0.3,
minRotation = pi/2, maxRotation = pi/2)
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
tweet_cleaned = read.csv("/Users/nihaozheng/Desktop/Visualization/project/twitter/tweet.csv")
View(tweet_cleaned)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
?wordcloud2
runApp()
runApp()
runApp()
